{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64102c98-128f-48db-a98d-46316d70fd38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from inference import predict_ensemble_topk, get_clean_class_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3913298a-1f92-4b58-a1d2-a434cd943377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Performance summaries (as measured during training/eval) ---\n",
    "PERF = {\n",
    "    \"ResNet50\": {\n",
    "        \"TRAIN\": {\"Accuracy\": 0.9348, \"Precision\": 0.9400, \"Recall\": 0.9386, \"F1 Score\": 0.9389, \"AUC\": 0.9953},\n",
    "        \"VAL\":   {\"Accuracy\": 0.7345, \"Precision\": 0.7646, \"Recall\": 0.7494, \"F1 Score\": 0.7512, \"AUC\": 0.9570},\n",
    "        \"TEST\":  {\"Accuracy\": 0.7924, \"Precision\": 0.8122, \"Recall\": 0.7868, \"F1 Score\": 0.7873, \"AUC\": 0.9716},\n",
    "    },\n",
    "    \"ResNet101\": {\n",
    "        \"TRAIN\": {\"Accuracy\": 0.9209, \"Precision\": 0.9280, \"Recall\": 0.9331, \"F1 Score\": 0.9290, \"AUC\": 0.9948},\n",
    "        \"VAL\":   {\"Accuracy\": 0.7530, \"Precision\": 0.7698, \"Recall\": 0.7764, \"F1 Score\": 0.7673, \"AUC\": 0.9594},\n",
    "        \"TEST\":  {\"Accuracy\": 0.7661, \"Precision\": 0.7717, \"Recall\": 0.7656, \"F1 Score\": 0.7635, \"AUC\": 0.9681},\n",
    "    },\n",
    "    \"EfficientNetB0\": {\n",
    "        \"TRAIN\": {\"Accuracy\": 0.9385, \"Precision\": 0.9420, \"Recall\": 0.9390, \"F1 Score\": 0.9398, \"AUC\": 0.9954},\n",
    "        \"VAL\":   {\"Accuracy\": 0.7530, \"Precision\": 0.7712, \"Recall\": 0.7549, \"F1 Score\": 0.7551, \"AUC\": 0.9592},\n",
    "        \"TEST\":  {\"Accuracy\": 0.7787, \"Precision\": 0.7961, \"Recall\": 0.7787, \"F1 Score\": 0.7816, \"AUC\": 0.9697},\n",
    "    },\n",
    "    \"VGG16\": {\n",
    "        \"TRAIN\": {\"Accuracy\": 0.9256, \"Precision\": 0.9314, \"Recall\": 0.9259, \"F1 Score\": 0.9275, \"AUC\": 0.9948},\n",
    "        \"VAL\":   {\"Accuracy\": 0.7199, \"Precision\": 0.7357, \"Recall\": 0.7212, \"F1 Score\": 0.7234, \"AUC\": 0.9556},\n",
    "        \"TEST\":  {\"Accuracy\": 0.7766, \"Precision\": 0.7900, \"Recall\": 0.7678, \"F1 Score\": 0.7660, \"AUC\": 0.9697},\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4a0f2e2b-2097-4f16-a52d-243050750d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_df_for(model_name: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for split in [\"TRAIN\",\"VAL\",\"TEST\"]:\n",
    "        m = PERF[model_name][split]\n",
    "        rows.append({\"Split\": split, **m})\n",
    "    df = pd.DataFrame(rows, columns=[\"Split\",\"Accuracy\",\"Precision\",\"Recall\",\"F1 Score\",\"AUC\"])\n",
    "    return df\n",
    "\n",
    "def perf_summary_text() -> str:\n",
    "    # highlight best on TEST for Accuracy and F1\n",
    "    test_acc = {m: PERF[m][\"TEST\"][\"Accuracy\"] for m in PERF}\n",
    "    test_f1  = {m: PERF[m][\"TEST\"][\"F1 Score\"] for m in PERF}\n",
    "    best_acc_model = max(test_acc, key=test_acc.get)\n",
    "    best_f1_model  = max(test_f1,  key=test_f1.get)\n",
    "    return (\n",
    "        f\"**Best TEST Accuracy:** {best_acc_model} ({test_acc[best_acc_model]:.4f})  \\n\"\n",
    "        f\"**Best TEST F1 Score:** {best_f1_model} ({test_f1[best_f1_model]:.4f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c6ecf9d-2b38-42dd-94c6-06318247355b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'model': 'EfficientNetB0',\n",
       "   'top1_class': 'Plastic',\n",
       "   'top1_prob': 0.9378593564033508},\n",
       "  {'model': 'ResNet101/100',\n",
       "   'top1_class': 'Paper',\n",
       "   'top1_prob': 0.9998509883880615},\n",
       "  {'model': 'ResNet50', 'top1_class': 'Paper', 'top1_prob': 1.0},\n",
       "  {'model': 'VGG16', 'top1_class': 'Textile Trash', 'top1_prob': 1.0}],\n",
       " [('Paper', 0.49996273774646705),\n",
       "  ('Textile Trash', 0.2510010533537873),\n",
       "  ('Plastic', 0.23446483471576138),\n",
       "  ('Cardboard', 0.014571246418529549)],\n",
       " [0.014571246418529549,\n",
       "  1.5611732145686615e-34,\n",
       "  3.381596372479674e-13,\n",
       "  9.355717414556804e-12,\n",
       "  1.4223785677671047e-15,\n",
       "  0.49996273774646705,\n",
       "  0.23446483471576138,\n",
       "  0.2510010533537873,\n",
       "  1.2775575943437151e-07],\n",
       " 178.24077606201172,\n",
       " ['Cardboard',\n",
       "  'Food Organics',\n",
       "  'Glass',\n",
       "  'Metal',\n",
       "  'Miscellaneous Trash',\n",
       "  'Paper',\n",
       "  'Plastic',\n",
       "  'Textile Trash',\n",
       "  'Vegetation'],\n",
       " {'EfficientNetB0': [0.05828498676419258,\n",
       "   6.244692975065955e-34,\n",
       "   3.9279975090166924e-23,\n",
       "   3.742287035812808e-11,\n",
       "   5.6895143774765046e-15,\n",
       "   1.9054104117689285e-19,\n",
       "   0.9378593564033508,\n",
       "   0.003855193732306361,\n",
       "   5.106473395244393e-07],\n",
       "  'ResNet101/100': [0.0,\n",
       "   0.0,\n",
       "   4.1218236732576616e-19,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.9998509883880615,\n",
       "   0.0,\n",
       "   0.0001490384602220729,\n",
       "   0.0],\n",
       "  'ResNet50': [1.9513906469308177e-35,\n",
       "   0.0,\n",
       "   1.3526381620679317e-12,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   6.674868874328374e-38,\n",
       "   0.0],\n",
       "  'VGG16': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.3759687431899322e-20,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   3.7570777045026205e-10]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('/Users/jiteshmishra/Documents/CodingLanguages/Python/Academics/DSCI 552/Final Project/data/RealWaste/6-Paper/Paper_16.jpg')\n",
    "# name,top3, probs, ms = predict_ensemble_topk(img, topk=4)\n",
    "per_model, ensemble_topk, agg, latency_ms, classes_clean, per_model_probs=predict_ensemble_topk(img, topk=4)\n",
    "# top3, ms\n",
    "per_model, ensemble_topk, agg, latency_ms, classes_clean ,per_model_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31185b15-937b-487f-a429-ed647ef8bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# MODELS_DIR = os.getenv(\"MODELS_DIR\", \"models\")\n",
    "# CLASS_NAMES_PATH = os.getenv(\"CLASS_NAMES_PATH\", \"models/class_names.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e8cce-9879-4b22-ab8b-68d758bd788e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(CLASS_NAMES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "#     loaded = json.load(f)\n",
    "# if isinstance(loaded, dict):\n",
    "#     name_to_idx = loaded\n",
    "#     CLASS_NAMES = [None] * (max(name_to_idx.values()) + 1)\n",
    "#     for name, idx in name_to_idx.items():\n",
    "#         CLASS_NAMES[idx] = name\n",
    "# else:\n",
    "#     CLASS_NAMES = loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea03e83d-72f4-49f8-a04e-aa5d726a0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS = []\n",
    "# for fname in sorted(os.listdir(MODELS_DIR)):\n",
    "#     if fname.endswith((\".keras\", \".h5\")):\n",
    "#         path = os.path.join(MODELS_DIR, fname)\n",
    "#         m = tf.keras.models.load_model(path, compile=False)\n",
    "#         MODELS.append(m)\n",
    "#         print(f\"[inference] Loaded model: {path}\")\n",
    "\n",
    "# if not MODELS:\n",
    "#     raise FileNotFoundError(\"No model files (*.keras/*.h5) found in models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e9336-562a-478f-8e6c-9f0994dfc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     num_out = int(MODELS[0].outputs[0].shape[-1])\n",
    "# except Exception:\n",
    "#     num_out = len(CLASS_NAMES)\n",
    "# if len(CLASS_NAMES) != num_out:\n",
    "#     raise ValueError(\n",
    "#         f\"Class count mismatch: model outputs {num_out}, \"\n",
    "#         f\"class_names.json has {len(CLASS_NAMES)}.\"\n",
    "#     )\n",
    "\n",
    "# print(f\"[inference] Loaded {len(MODELS)} model(s); {len(CLASS_NAMES)} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5c543c2-0052-4fbb-9e65-f189c2c1a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image):\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "    per_model, ensemble_top3, probs, latency_ms, classes_clean, per_model_probs = predict_ensemble_topk(\n",
    "        image, topk=3, aggregate=\"mean\"\n",
    "    )\n",
    "\n",
    "    # 1) Per-model table (as you already had)\n",
    "    df_models = pd.DataFrame(per_model).sort_values(\"top1_prob\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # 2) Winner banner\n",
    "    best_row = df_models.iloc[0]\n",
    "    winner_text = f\"## üèÜ Most confident: **{best_row['top1_class']}**  \\n*{best_row['model']}* with prob **{best_row['top1_prob']:.3f}**\"\n",
    "\n",
    "    # 3) VGG16 Top-3 table (instead of ensemble)\n",
    "    # Find VGG16 key (robust to naming)\n",
    "    vgg_key = None\n",
    "    for k in per_model_probs.keys():\n",
    "        if \"vgg\" in k.lower():\n",
    "            vgg_key = k\n",
    "            break\n",
    "\n",
    "    if vgg_key is None:\n",
    "        vgg_note = \"### (VGG16 not loaded ‚Äî showing ensemble Top-3 instead)\"\n",
    "        df_vgg = pd.DataFrame(ensemble_top3, columns=[\"Class\", \"Probability\"])\n",
    "    else:\n",
    "        vgg_probs = per_model_probs[vgg_key]\n",
    "        # build class‚Üíprob pairs, sorted desc, take top-3\n",
    "        pairs = list(zip(classes_clean, vgg_probs))\n",
    "        pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "        df_vgg = pd.DataFrame(pairs[:1], columns=[\"Class\", \"Probability\"])\n",
    "        vgg_note = \"### Based on our testing, **VGG16** had the best test metric.  \\nVGG16 class probabilities for the uploaded image:\"\n",
    "\n",
    "    # 4) Classes list and latency\n",
    "    classes_joined = \" | \".join(classes_clean)\n",
    "    classes_markdown = \"The uploaded image is classified under these classes: \"+ classes_joined\n",
    "    latency_text = f\"Latency: {latency_ms:.1f} ms\"\n",
    "\n",
    "    return winner_text, df_models, vgg_note, df_vgg, classes_markdown, latency_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57949c2b-718f-4f92-b4b7-4afa5d6f6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_inference(image):\n",
    "#     if not isinstance(image, Image.Image):\n",
    "#         image = Image.fromarray(image)\n",
    "\n",
    "#     per_model, ensemble_top3, probs, latency_ms, classes_clean = predict_ensemble_topk(\n",
    "#         image, topk=3, aggregate=\"mean\"\n",
    "#     )\n",
    "\n",
    "#     # 1) Per-model table\n",
    "#     df_models = pd.DataFrame(per_model)  # columns: model, top1_class, top1_prob\n",
    "#     df_models = df_models.sort_values(\"top1_prob\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "#     # 2) Winner banner (highest single-model prob)\n",
    "#     best_row = df_models.iloc[0]\n",
    "#     winner_text = f\"## üèÜ Most confident: **{best_row['top1_class']}**  \\n*{best_row['model']}* with prob **{best_row['top1_prob']:.3f}**\"\n",
    "\n",
    "#     # 3) Ensemble Top-3 table\n",
    "#     df_ens = pd.DataFrame(ensemble_top3, columns=[\"Class\", \"Probability\"])\n",
    "\n",
    "#     # 4) Classes list (cleaned)\n",
    "#     classes_markdown = \" | \".join(classes_clean)\n",
    "\n",
    "#     # 5) Latency\n",
    "#     latency_text = f\"Latency: {latency_ms:.1f} ms\"\n",
    "\n",
    "#     return winner_text, df_models, df_ens, classes_markdown, latency_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8417c39-4e0a-4ce5-9d6d-546a34a9b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_inference(image):\n",
    "#     # Gradio may pass numpy array; convert to PIL\n",
    "#     if not isinstance(image, Image.Image):\n",
    "#         image = Image.fromarray(image)\n",
    "\n",
    "#     top3, probs, latency_ms = predict_ensemble_topk(image, topk=3, aggregate=\"mean\")\n",
    "\n",
    "#     # Prepare outputs\n",
    "#     label_text = f\"Top-1: {top3[0][0]} ({top3[0][1]:.3f}) ‚Äî {latency_ms:.1f} ms\"\n",
    "#     df = pd.DataFrame(top3, columns=[\"Class\", \"Probability\"])\n",
    "#     return label_text, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77f05f7b-52d3-43ef-9506-628c64420aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(title=\"‚ôªÔ∏è Waste Classifier\") as demo:\n",
    "    gr.Markdown(\"# ‚ôªÔ∏è Waste Classifier\")\n",
    "\n",
    "    with gr.Tabs():\n",
    "        # --- Tab 1: Inference ---\n",
    "        with gr.TabItem(\"Classify\"):\n",
    "            gr.Markdown(\"Upload an image **or** use your **camera**. The app shows each model‚Äôs top-1, the most confident model, and **VGG16**‚Äôs Top-3.\")\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    inp = gr.Image(label=\"Input Image\", sources=[\"upload\",\"webcam\"], type=\"pil\")\n",
    "                    btn = gr.Button(\"Predict\")\n",
    "                with gr.Column():\n",
    "                    winner_md = gr.Markdown()\n",
    "                    models_df = gr.Dataframe(headers=[\"model\",\"top1_class\",\"top1_prob\"], interactive=False)\n",
    "                    # vgg_note_md = gr.Markdown()\n",
    "                    # vgg_df = gr.Dataframe(headers=[\"Class\",\"Probability\"], interactive=False)\n",
    "                    classes_md = gr.Markdown()\n",
    "                    latency_md = gr.Markdown()\n",
    "            btn.click(\n",
    "                fn=run_inference,\n",
    "                inputs=inp,\n",
    "                outputs=[winner_md, models_df, vgg_note_md, vgg_df, classes_md, latency_md]\n",
    "            )\n",
    "\n",
    "        # --- Tab 2: Performance ---\n",
    "        with gr.TabItem(\"Performance\"):\n",
    "            gr.Markdown(\"## üìä Model Performance Summary\")\n",
    "            perf_summary = gr.Markdown(perf_summary_text())\n",
    "\n",
    "            # Show all four in accordions\n",
    "            with gr.Accordion(\"ResNet50\", open=False):\n",
    "                res50_df = gr.Dataframe(value=perf_df_for(\"ResNet50\"), interactive=False)\n",
    "            with gr.Accordion(\"ResNet101\", open=False):\n",
    "                res101_df = gr.Dataframe(value=perf_df_for(\"ResNet101\"), interactive=False)\n",
    "            with gr.Accordion(\"EfficientNetB0\", open=False):\n",
    "                eff_df = gr.Dataframe(value=perf_df_for(\"EfficientNetB0\"), interactive=False)\n",
    "            with gr.Accordion(\"VGG16\", open=False):\n",
    "                vgg_df_perf = gr.Dataframe(value=perf_df_for(\"VGG16\"), interactive=False)\n",
    "\n",
    "    gr.Markdown(\"‚Äî Powered by Keras Transfer Learning + Gradio ‚Äî\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9b0971cb-4e36-4280-bfdd-85dc276e111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gr.Blocks(title=\"‚ôªÔ∏è Waste Classifier\") as demo:\n",
    "#     gr.Markdown(\"# ‚ôªÔ∏è Waste Classifier (Ensemble)\")\n",
    "#     gr.Markdown(\"Upload an image **or** use your **camera**. The app shows each model‚Äôs top-1, the most confident model, and **VGG16**‚Äôs Top-3.\")\n",
    "\n",
    "#     with gr.Row():\n",
    "#         with gr.Column():\n",
    "#             inp = gr.Image(label=\"Input Image\", sources=[\"upload\",\"webcam\"], type=\"pil\")\n",
    "#             btn = gr.Button(\"Predict\")\n",
    "#         with gr.Column():\n",
    "#             winner_md = gr.Markdown()\n",
    "#             models_df = gr.Dataframe(headers=[\"model\",\"top1_class\",\"top1_prob\"], interactive=False)\n",
    "#             # vgg_note_md = gr.Markdown()\n",
    "#             # vgg_df = gr.Dataframe(headers=[\"Class\",\"Probability\"], interactive=False)\n",
    "#             classes_md = gr.Markdown()\n",
    "#             latency_md = gr.Markdown()\n",
    "\n",
    "#     btn.click(\n",
    "#         fn=run_inference,\n",
    "#         inputs=inp,\n",
    "#         outputs=[winner_md, models_df, vgg_note_md, vgg_df, classes_md, latency_md]\n",
    "#     )\n",
    "\n",
    "#     gr.Markdown(\"‚Äî Powered by Keras Transfer Learning + Gradio ‚Äî\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fdb1d2d-859e-45f2-8990-902b08eb586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gr.Blocks(title=\"‚ôªÔ∏è Waste Classifier\") as demo:\n",
    "#     gr.Markdown(\"# ‚ôªÔ∏è Waste Classifier (Ensemble)\")\n",
    "#     gr.Markdown(\"Upload an image **or** use your **camera**. The app shows each model‚Äôs top-1, the most confident model, and the ensemble Top-3.\")\n",
    "\n",
    "#     with gr.Row():\n",
    "#         with gr.Column():\n",
    "#             inp = gr.Image(label=\"Input Image\", sources=[\"upload\",\"webcam\"], type=\"pil\")\n",
    "#             btn = gr.Button(\"Predict\")\n",
    "#         with gr.Column():\n",
    "#             winner_md = gr.Markdown()\n",
    "#             models_df = gr.Dataframe(headers=[\"model\",\"top1_class\",\"top1_prob\"], interactive=False)\n",
    "#             ens_df = gr.Dataframe(headers=[\"Class\",\"Probability\"], interactive=False)\n",
    "#             classes_md = gr.Markdown()\n",
    "#             latency_md = gr.Markdown()\n",
    "\n",
    "#     btn.click(\n",
    "#         fn=run_inference,\n",
    "#         inputs=inp,\n",
    "#         outputs=[winner_md, models_df, ens_df, classes_md, latency_md]\n",
    "#     )\n",
    "\n",
    "#     gr.Markdown(\"‚Äî Powered by Keras Transfer Learning + Gradio ‚Äî\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "acb0db63-8c8f-4d86-aaaf-91975e6b4fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f9ddca-3f06-49a6-a322-5ac7dcdb6f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# with gr.Blocks(title=\"‚ôªÔ∏è Waste Classifier\") as demo:\n",
    "#     gr.Markdown(\"# ‚ôªÔ∏è Waste Classifier (Ensemble of ResNet, VGG, EfficientNet)\")\n",
    "#     gr.Markdown(\"Upload an image **or** use your **camera** to classify waste into 9 categories.\")\n",
    "\n",
    "#     with gr.Row():\n",
    "#         with gr.Column():\n",
    "#             inp = gr.Image(\n",
    "#                 label=\"Input Image\",\n",
    "#                 sources=[\"upload\",\"webcam\"],\n",
    "#                 type=\"pil\",\n",
    "#                 streaming=False\n",
    "#             )\n",
    "#             btn = gr.Button(\"Predict\")\n",
    "#         with gr.Column():\n",
    "#             out_label = gr.Markdown()\n",
    "#             out_table = gr.Dataframe(\n",
    "#                 headers=[\"Class\",\"Probability\"],\n",
    "#                 interactive=False\n",
    "#             )\n",
    "\n",
    "#     btn.click(fn=run_inference, inputs=inp, outputs=[out_label, out_table])\n",
    "\n",
    "#     gr.Markdown(\"‚Äî Powered by Keras Transfer Learning + Gradio ‚Äî\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c1bd2-24e1-477d-877b-7b2530ff6c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d7caf-bd39-4140-a919-46f063eedd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8c064-71b8-4e53-9ec1-152b5866bd95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
